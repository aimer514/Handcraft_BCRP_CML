
current epoch  = 0
loss  = 0.4094336926937103
benign accuracy  = 0.8273
current epoch  = 1
loss  = 0.3957364857196808
benign accuracy  = 0.8664
current epoch  = 2
loss  = 0.29092124104499817
benign accuracy  = 0.8667
current epoch  = 3
loss  = 0.2698165476322174
benign accuracy  = 0.8937
current epoch  = 4
loss  = 0.2222186177968979
benign accuracy  = 0.8948
current epoch  = 5
Traceback (most recent call last):
  File "/Users/qyq/Desktop/Handcraft_BCRP_CML/main.py", line 69, in <module>
    for batch_idx, (data, label) in enumerate(train_loader):
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py", line 145, in __getitem__
    img = self.transform(img)
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/transforms/functional.py", line 139, in to_tensor
    if not (F_pil._is_pil_image(pic) or _is_numpy(pic)):
  File "/Users/qyq/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/transforms/_functional_pil.py", line 19, in _is_pil_image
    return isinstance(img, Image.Image)
